{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52f8dd9c",
   "metadata": {},
   "source": [
    "# Task-01 Worksheet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04af93a5",
   "metadata": {},
   "source": [
    "## Fetching S3 Bucket with dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef60088",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "  \n",
    "s3_resource = boto3.resource('s3')\n",
    "all_buckets = s3_resource.buckets.all()\n",
    "\n",
    "# Identify the SageMaker default S3 bucket that contains the dataset. \n",
    "# It is the bucket {sagemaker}-{region}-{account-id} that we are aiming \n",
    "# to identify programitaclly and using boto3 to create an object for the \n",
    "# same so that we can navigate it in the next steps.\n",
    "\n",
    "# {fill-in-code}\n",
    "\n",
    "jam_bucket = s3_resource.Bucket(BUCKET)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26454402",
   "metadata": {},
   "source": [
    "## Extracting Zipped Dataset into S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85854151",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import zipfile\n",
    "from io import BytesIO\n",
    "\n",
    "ZIPPED_DATA = 'radiography_train_data.zip'\n",
    "TRAIN_DATA_PREFIX = 'radiography_train_data'\n",
    "\n",
    "print (\"Unzipping \", ZIPPED_DATA)\n",
    "\n",
    "# Extract the zip file radiography_train_data.zip available on your Amazon S3 bucket. \n",
    "# After extracting the Zip file into the prefix radiography_train_data/, \n",
    "# remove any unwanted hidden files (example .DS_STORE, .ipynbcheckpoint).\n",
    "# {fill-in-code}\n",
    "\n",
    "print (\"Completed Unzipping Training Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93764d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing hidden files after unzipping, if any \n",
    "for obj in jam_bucket.objects.filter(Prefix=TRAIN_DATA_PREFIX+'/'):\n",
    "    if '/.' in obj.key:\n",
    "       s3_resource.Object(jam_bucket.name, obj.key).delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e122587e",
   "metadata": {},
   "source": [
    "## Extracting Zipped Dataset into S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbae0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "def get_size(bucket, path):\n",
    "    s3 = boto3.resource('s3')\n",
    "    my_bucket = s3.Bucket(bucket)\n",
    "    total_size = 0\n",
    "    image_count = 0\n",
    "    \n",
    "    # Calculate the average file-size of the .png images in \n",
    "    # your dataset inside the /train folder. \n",
    "    # {fill-in-code}\n",
    "    \n",
    "    return total_size, image_count\n",
    "\n",
    "folder_size, image_count = get_size(BUCKET, TRAIN_DATA_PREFIX+'/train')\n",
    "average_image_size = folder_size / image_count\n",
    "print (average_image_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_mxnet_p27",
   "language": "python",
   "name": "conda_amazonei_mxnet_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
